{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)  \n",
    "import helpers\n",
    "\n",
    "# Training file directory\n",
    "DATASET = os.path.join(ROOT_DIR, 'dataset')\n",
    "\n",
    "PATH = \"{}/{}\".format(DATASET, \"isic2016numpy\")\n",
    "# load data\n",
    "x_train = np.load(\"{}/x_train.npy\".format(PATH))\n",
    "y_train = np.load(\"{}/y_train.npy\".format(PATH))\n",
    "x_train.shape, y_train.shape\n",
    "\n",
    "MODEL_PATH = os.path.join(ROOT_DIR, \"models\")\n",
    "print(ROOT_DIR)\n",
    "print(os.listdir(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load translation model\n",
    "# b2m.h5\n",
    "model_name = 'generator_isic2016_b2m_100.h5'\n",
    "model = load_model(os.path.join(MODEL_PATH, model_name), custom_objects={'InstanceNormalization':InstanceNormalization})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    \n",
    "    if img.shape[0] != 256:\n",
    "        print(\"Resizing image..\")\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "    \n",
    "    # Normalize image as the trained distribution\n",
    "    \n",
    "    img = img/127.5 - 1.\n",
    "    \n",
    "    # Normalize imgae [0, 1]\n",
    "    #img = img.astype('float32')\n",
    "    #img /= 255.\n",
    "    \n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = model.predict(img)\n",
    "    img = np.squeeze(img, axis=0)\n",
    "    \n",
    "    \n",
    "    # Rescale to [0,1]\n",
    "    #img = 0.5 * img + 0.5\n",
    "    img = (img - np.min(img))/np.ptp(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def oversample(x, y, model):\n",
    "    '''\n",
    "    Some cool stuff\n",
    "    INPUT\n",
    "        x: \n",
    "        y:\n",
    "        model:\n",
    "        \n",
    "    OUTPUT\n",
    "        New folder in the current directory.\n",
    "    '''\n",
    "    \n",
    "    print(\"Before oversampling :\", x.shape, y.shape)\n",
    "    \n",
    "    \n",
    "    # majority class\n",
    "    majority_samples = []\n",
    "    for img, label in zip(x, y):\n",
    "        if label[1] == 0:\n",
    "            majority_samples.append(img)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # numpy array of majority classes\n",
    "    majority_samples = np.array(majority_samples)\n",
    "    \n",
    "    # minority generated samples\n",
    "    synthetic_samples = []\n",
    "    \n",
    "    # iterate over majority samples and generate minority class\n",
    "    for img in tqdm(majority_samples):\n",
    "        \n",
    "        # translate to malignant\n",
    "        pred = predict(model, img)\n",
    "        synthetic_samples.append(pred)\n",
    "    \n",
    "    # make labels for generated minority classes\n",
    "    y_syn = np.array([1 for _ in range(len(synthetic_samples))])\n",
    "    y_syn = np_utils.to_categorical(y_syn, 2)\n",
    "    \n",
    "    # Scale training set to [0, 1]\n",
    "    x = x.astype('float32')\n",
    "    x /= 255\n",
    "    \n",
    "    # merge and shuffle training and generated samples\n",
    "    x_balanced = np.concatenate( (x, synthetic_samples), axis = 0)\n",
    "    y_balanced = np.concatenate( (y, y_syn), axis = 0)\n",
    "    x_balanced, y_balanced = helpers.shuffle_dataset(x_balanced, y_balanced)\n",
    "    \n",
    "    assert len(majority_samples) == len(synthetic_samples), \"This should be same! If not, check model code\"\n",
    "    assert len(x_balanced) == len(synthetic_samples) + len(x_train), \"Check oversampler code\"\n",
    "    print(\"After oversampling: \", x_balanced.shape, y_balanced.shape)\n",
    "    \n",
    "    return majority_samples, synthetic_samples, x_balanced, y_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw, gen, x_new, y_new = oversample(x_train, y_train, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import rand\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = np.random.choice(np.array(gen).shape[0], 30, replace=False)\n",
    "raw = np.array(raw)\n",
    "x = raw[index]\n",
    "\n",
    "a, b = 5, 6\n",
    "x = np.reshape(x, (a, b, 256, 256, 3))\n",
    "\n",
    "\n",
    "test_data = x\n",
    "r, c = test_data.shape[0], test_data.shape[1]\n",
    "cmaps = [['viridis', 'binary'], ['plasma', 'coolwarm'], ['Greens', 'copper']]\n",
    "\n",
    "heights = [a[0].shape[0] for a in test_data]\n",
    "widths = [a.shape[1] for a in test_data[0]]\n",
    "\n",
    "fig_width = 15.  # inches\n",
    "fig_height = fig_width * sum(heights) / sum(widths)\n",
    "\n",
    "f, axarr = plt.subplots(r,c, figsize=(fig_width, fig_height),\n",
    "        gridspec_kw={'height_ratios':heights})\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axarr[i, j].imshow(test_data[i][j])\n",
    "        axarr[i, j].axis('off')\n",
    "        \n",
    "plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
    "#plt.savefig('{}/{}.png'.format(\"{}/outputs/\".format(ROOT_DIR), \"beforegan\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import rand\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gen = np.array(gen)\n",
    "x = gen[index]\n",
    "\n",
    "a, b = 5, 6\n",
    "x = np.reshape(x, (a, b, 256, 256, 3))\n",
    "\n",
    "\n",
    "test_data = x\n",
    "r, c = test_data.shape[0], test_data.shape[1]\n",
    "cmaps = [['viridis', 'binary'], ['plasma', 'coolwarm'], ['Greens', 'copper']]\n",
    "\n",
    "heights = [a[0].shape[0] for a in test_data]\n",
    "widths = [a.shape[1] for a in test_data[0]]\n",
    "\n",
    "fig_width = 15.  # inches\n",
    "fig_height = fig_width * sum(heights) / sum(widths)\n",
    "\n",
    "f, axarr = plt.subplots(r,c, figsize=(fig_width, fig_height),\n",
    "        gridspec_kw={'height_ratios':heights})\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axarr[i, j].imshow(test_data[i][j])\n",
    "        axarr[i, j].axis('off')\n",
    "        \n",
    "plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
    "#plt.savefig('{}/{}.png'.format(\"{}/outputs/\".format(ROOT_DIR), \"aftergan\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new.shape, y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory\n",
    "helpers.create_directory(\"{}/dataset/isic2016gan/\".format(ROOT_DIR))\n",
    "\n",
    "# Save\n",
    "np.save(\"{}/dataset/isic2016gan/{}{}.npy\".format(ROOT_DIR, \"x_\", \"upsampled\"), x_new)\n",
    "np.save(\"{}/dataset/isic2016gan/{}{}.npy\".format(ROOT_DIR, \"y_\", \"upsampled\"), y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
